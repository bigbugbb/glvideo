开发Lobby App过程中，设计提出了渲染3d明信片并分享明信片视频的需求。当时iOS那边用SceneKit就可以实现，Android这边没有相应工具链，于是我只好DIY了一套工具自己实现。
为了实现渲染，我先加入了跟OpenGLES渲染相关的工具，包括纹理操作，基础shader, FBO, 自己的基础Renderer类和CustomGLSurfaceView，自己的RenderThread等。同时把每个渲染元素抽象成一个Drawer，分开管理各自的顶点坐标、纹理坐标、坐标变换，坐标数据加载，viewport和具体绘制逻辑。
为了实现录制，加入了自己的MediaCodec硬编码逻辑和编码器端的Renderer。该Renderer主要为了解耦encoder和传给encoder的纹理数据源，因为源纹理尺寸可以和encoder编码尺寸不一致，同时这也赋予了encoder端对纹理进行后处理的灵活度。
开发过程中为了实现不同线程的GL资源共享，参考字节流动的技术文章实现了灵活的EGL Context管理（主要涉及EGL资源创建，资源到线程的绑定和解绑定）。
渲染的卡片上本身还有一个视频，于是又加入了MediaCodec硬解和帧缓冲区拷贝。
基于这套技术工具，后来又实现了给视频加水印，加开头和结尾内容，用于标记视频源来自Lobby App。

后来设计又想在进入App后直接开前置摄像头进行采集，并将采集的视频帧作为首页背景显示，并在特定场景下加入毛玻璃效果。
于是我又加入了基于CameraX的视频帧采集、渲染和简单特效。

Lobby App内可以进入语音房，在语音房里的speaker可以开视频，房主可以发起房间快照转视频并分享的功能。具体来说，首先需要同步房员状态（包括将座位UI动态改变成九宫格，Activity界面上显示倒计时等），接着需要采集房主自己和房员在倒计时结束后一秒内的所有视频帧（240*240的尺寸，最多同时收集9个源，framerate不大于24）。
由于源数据帧来自不同线程，为了在采集时实现纹理共享，又实现了简单的纹理池（纹理池自己有维护一个GL线程，通过将纹理池的EGLContext分享给绑定到不同EGLContext的数据采集线程，实现纹理共享）。接着为了将ByteBuffer数据上传到具体的纹理缓冲，又加入了PBO做性能优化。

Lobby App临死前又加入了设置用户webp格式头像的功能，这个webp文件需要通过视频采集和裁剪获得，于是又接入了ffmpeg后处理，将裁剪的mp4文件转成webp。

在以上整个开发过程中，基于对现有代码复用、处理逻辑简化、线程操作简化、降低学习成本等考虑，实现了一套基于图和携程的Kotlin端视频处理简易框架，这里打包成库和SampleApp。
在以后的技术积累中还会继续完善这个框架，未来的目标是并逐步加入native部分，并在native部分整合ffmpeg，通过ffmpeg的接口取代MediaCodec，简化上层逻辑，并给native曾提供更多灵活性。
